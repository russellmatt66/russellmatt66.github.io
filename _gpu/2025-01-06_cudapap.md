---
layout: post
title: CUDA - How to Plug and Play with your GPU
date: 2025-01-06
collection: gpu
---
WIP - Copied from a LinkedIn draft, and still working on it :)

Why do I love CUDA? One big reason is how it lets you just Plug and Play.


Before CUDA was developed by Ian Buck and his team at NVIDIA in the early-2000s, programming a GPU meant translating your application into the language of shaders. These are essentially specifications for how triangles in a mesh of them are colored in. 


This also meant working with graphics languages like OpenGL, or Vulkan, which require you to engage in the laborious process of talking directly to the GPU. CUDA abstracts away these worries, and presents applications programmers with the idea of an execution configuration, instead. 


This sounds intimidating, but it's actually a genius idea, as it allows one to focus on writing "MPI-like" kernels that the execution configuration merely specifies the structure of the thread teams for. When a kernel is launched each thread will go through and execute its statements, similar to the way MPI works. 


In general, these teams take the structure of a 3D block of threads, which are themselves a member of a 3D grid of threadblocks, each of which can have at most 1024 threads in total. This 6D structure is what's known as an "execution configuration", and every global device kernel requires one to launch. 


One of the first keys to parallel programming is finding a way to partition the work amongst your thread team. CUDA makes this easy by assigning global and local coordinates to the threads. 


The code snippet below shows what this looks like in practice using the example of a global device kernel that solves the Ideal MHD system of PDEs using an approach that minimizes memory operations by leveraging register variables. 


The local coordinates of a thread, meaning in its threadblock, are given by threadIdx.{x,y,z}. 


The number of threads along a dimension of the threadblocks are given by blockDim.{x,y,z}. 


The global coordinates of the threadblocks in the execution grid are given by blockIdx.{x,y,z}.  


The number of threadblocks along a given dimension of the grid is given by gridDim.{x,y,z}


You can use these innate values to index a given thread into, and then stride through, a computational grid. Since each thread has a unique set of coordinates, you can prevent data hazards by striding them along a dimension of the computational grid a distance equal to the number of threads along the same dimension of the execution grid. 


This makes developing a first-pass implementation fairly straightforward once you see how this works, and after all, developer time is more valuable than compute time!


